{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining with Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "combined = pd.concat([train, test], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_name(s): \n",
    "    a, b = s.split(',')\n",
    "    family_name = a.strip()\n",
    "    title = b.split('.')[0].strip()\n",
    "    first_name = b.split('.')[1].split()[0].strip()\n",
    "    return (first_name.replace('(', '').replace(')', ''), title, family_name)\n",
    "\n",
    "def parse_cabin_letter(column):\n",
    "    letter_pat = re.compile('([A-Za-z])\\d+')\n",
    "    return list(map(lambda x: letter_pat.findall(str(x))[0] if letter_pat.findall(str(x)) else pd.np.nan, column.values.tolist()))\n",
    "\n",
    "def parse_ticket_number(column):\n",
    "    number_pat = re.compile('\\d{3,}')\n",
    "    numbers = map(lambda x: number_pat.findall(x)[0] if number_pat.findall(x) else pd.np.nan, column)\n",
    "    return pd.Series(numbers)\n",
    "\n",
    "\n",
    "def get_friendship_group(df):\n",
    "    friendship_group_counter = 0\n",
    "    if 'family_name' not in df.columns:\n",
    "        family_names = pd.Series(map(lambda x: parse_name(x)[-1], df.Name))\n",
    "    else:\n",
    "        family_names = df.family_name\n",
    "    cabins = pd.Series(map(parse_cabin_letter, df.Cabin))\n",
    "    ticket_grouping = []\n",
    "    for family, count in family_names.value_counts().items():\n",
    "        family_mask = family_names == family\n",
    "        \n",
    "        if count == 1:\n",
    "            ticket_grouping.append(friendship_group_counter)\n",
    "            friendship_group_counter += 1\n",
    "            continue\n",
    "\n",
    "            \n",
    "def get_family_name(df):\n",
    "    family_names = pd.Series(map(lambda x: parse_name(x)[-1], df.Name))\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:,'family_name'] = family_names\n",
    "    return df_\n",
    "            \n",
    "def get_ticket_group(df):\n",
    "    df_ = df.copy()\n",
    "    grouped = df.Ticket.groupby(parse_ticket_number(df.Ticket))\n",
    "    for ind, key in enumerate(grouped.indices):\n",
    "        df_.loc[grouped.indices[key], 'ticket_group'] = ind\n",
    "    return df_\n",
    "\n",
    "def get_cabin_letter(df):\n",
    "    df_ = df.copy()\n",
    "    cabins = parse_cabin_letter(df.Cabin)\n",
    "    df_.loc[:, 'cabin_na'] = pd.isnull(df.Cabin)\n",
    "    df_.loc[:, 'cabin'] = cabins\n",
    "    return df_\n",
    "\n",
    "def get_is_alone(df):\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:, 'is_alone'] = (df.loc[:, 'Parch'] + df.loc[:, 'SibSp'] + 1 == 1)\n",
    "    return df_\n",
    "\n",
    "def get_titles(df):\n",
    "    df_ = df.copy()\n",
    "    titles = pd.Series(map(lambda x: parse_name(x)[1], df.Name))\n",
    "    df_.loc[:, 'title'] = titles\n",
    "    return df_\n",
    "\n",
    "def discretize_faries(df, ngroups=3):\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:, 'fares'] = pd.cut(df_.loc[:,'Fare'], ngroups, labels=False)\n",
    "    return df_\n",
    "\n",
    "def estimate_age(df):\n",
    "    estimates = []\n",
    "    for ind, row in df.loc[df.Age.isnull(),:].iterrows():\n",
    "        if row.title in ['Master', 'Mr', 'Miss', 'Rev', 'Dr']:\n",
    "            estimates.append(df.groupby(['title', 'Sex']).median().loc[[row.title, row.Sex],'Age'].values[0])\n",
    "        else:\n",
    "            estimates.append(df.groupby(['Sex']).median().loc[[row.Sex], 'Age'].values[0])\n",
    "    df_ = df.copy()\n",
    "    df_.loc[df.Age.isnull(), 'Age'] = estimates\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpipes.pfunc import *\n",
    "\n",
    "preprocessing_pipeline = (('add_groups', get_ticket_group, {}),\n",
    "                          ('add_cabins', get_cabin_letter, {}),\n",
    "                          ('add_isalone', get_is_alone, {}),\n",
    "                          ('add_titles', get_titles, {}),\n",
    "                          ('convert_fares', discretize_faries, {'ngroups': 3}),\n",
    "                          ('add_ticket_group', get_ticket_group, {}),\n",
    "                          ('fill_embarked', fill_na_simple, {'colnames': ('Embarked',),\n",
    "                                                             'methods': (lambda x: pd.Series(x).mode()[0],)}),\n",
    "                          ('add_family_name', get_family_name, {}),\n",
    "                          ('add_ages', estimate_age, {}),\n",
    "                          ('drop_columns', drop_columns, {'colnames': ('Survived',\n",
    "                                                                      'PassengerId',\n",
    "                                                                      'SibSp',\n",
    "                                                                      'Parch',\n",
    "                                                                      'Ticket',\n",
    "                                                                      'Fare',\n",
    "                                                                     )}),\n",
    "                          \n",
    "                         )\n",
    "\n",
    "def process(pipeline, data):\n",
    "    data_ = data.copy()\n",
    "    for name, func, kwargs in pipeline:\n",
    "        print(\"=========== Step: %s ===========\" % name)\n",
    "        data_ = func(data_, **kwargs)\n",
    "        print(\"=\" * 40)\n",
    "    return data_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps (feature engeneering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed  = process(preprocessing_pipeline, combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = processed.groupby(['title', 'Sex']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.loc[['Capt', 'male'],'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
