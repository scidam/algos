{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining with Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster, single, complete\n",
    "from collections.abc import Iterable\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "combined = pd.concat([train, test], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_name(s): \n",
    "    a, b = s.split(',')\n",
    "    family_name = a.strip()\n",
    "    title = b.split('.')[0].strip()\n",
    "    first_name = b.split('.')[1].split()[0].strip()\n",
    "    return (first_name.replace('(', '').replace(')', ''), title, family_name)\n",
    "\n",
    "def parse_cabin_letter(column):\n",
    "    letter_pat = re.compile('([A-Za-z])\\d+')\n",
    "    return list(map(lambda x: letter_pat.findall(str(x))[0] if letter_pat.findall(str(x)) else pd.np.nan, column.values.tolist()))\n",
    "\n",
    "def parse_ticket_number(column):\n",
    "    number_pat = re.compile('\\d{3,}')\n",
    "    numbers = map(lambda x: number_pat.findall(x)[0] if number_pat.findall(x) else pd.np.nan, column)\n",
    "    return pd.Series(numbers)\n",
    "\n",
    "\n",
    "def get_friendship_group(df):\n",
    "    friendship_group_counter = 0\n",
    "    if 'family_name' not in df.columns:\n",
    "        family_names = pd.Series(map(lambda x: parse_name(x)[-1], df.Name))\n",
    "    else:\n",
    "        family_names = df.family_name\n",
    "    cabins = pd.Series(map(parse_cabin_letter, df.Cabin))\n",
    "    ticket_grouping = []\n",
    "    for family, count in family_names.value_counts().items():\n",
    "        family_mask = family_names == family\n",
    "        \n",
    "        if count == 1:\n",
    "            ticket_grouping.append(friendship_group_counter)\n",
    "            friendship_group_counter += 1\n",
    "            continue\n",
    "\n",
    "            \n",
    "def get_family_name(df):\n",
    "    family_names = pd.Series(map(lambda x: parse_name(x)[-1], df.Name))\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:,'family_name'] = family_names\n",
    "    return df_\n",
    "            \n",
    "def get_ticket_group(df):\n",
    "    df_ = df.copy()\n",
    "    grouped = df.Ticket.groupby(parse_ticket_number(df.Ticket))\n",
    "    for ind, key in enumerate(grouped.indices):\n",
    "        df_.loc[grouped.indices[key], 'ticket_group'] = ind\n",
    "    return df_\n",
    "\n",
    "def get_cabin_letter(df):\n",
    "    df_ = df.copy()\n",
    "    cabins = parse_cabin_letter(df.Cabin)\n",
    "    df_.loc[:, 'cabin_na'] = pd.isnull(df.Cabin)\n",
    "    df_.loc[:, 'cabin'] = cabins\n",
    "    return df_\n",
    "\n",
    "def get_is_alone(df):\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:, 'is_alone'] = (df.loc[:, 'Parch'] + df.loc[:, 'SibSp'] + 1 == 1)\n",
    "    return df_\n",
    "\n",
    "def get_titles(df):\n",
    "    df_ = df.copy()\n",
    "    titles = pd.Series(map(lambda x: parse_name(x)[1], df.Name))\n",
    "    df_.loc[:, 'title'] = titles\n",
    "    return df_\n",
    "\n",
    "def discretize_faries(df, ngroups=3):\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:, 'fares'] = pd.cut(df_.loc[:,'Fare'], ngroups, labels=False)\n",
    "    return df_\n",
    "\n",
    "def estimate_age(df):\n",
    "    estimates = []\n",
    "    for ind, row in df.loc[df.Age.isnull(), :].iterrows():\n",
    "        # NOTE: Could be rewritten using vectorized notation\n",
    "        if row.title in ['Master', 'Mr', 'Miss', 'Rev', 'Dr']:\n",
    "            estimates.append(df.groupby(['title', 'Sex']).median().loc[[row.title, row.Sex],'Age'].values[0])\n",
    "        else:\n",
    "            estimates.append(df.groupby(['Sex', 'Pclass']).median().loc[[row.Sex], 'Age'].values[0])\n",
    "    df_ = df.copy()\n",
    "    df_.loc[df.Age.isnull(), 'Age'] = estimates\n",
    "    return df_\n",
    "\n",
    "\n",
    "def get_cabin_groups(df):\n",
    "    num_pat = re.compile('\\d+')\n",
    "    let_pat = re.compile('[a-zA-Z]')\n",
    "    LONG_DISTANCE = 5\n",
    "    MEDIUM_DISTANCE = 4\n",
    "    NORMAL_DISTANCE = 3\n",
    "    SMALL_DISTANCE = 2\n",
    "    LOW_DISTANCE = 1\n",
    "    EQUAL = 0\n",
    "    def cabin_distance(u, v):\n",
    "        _u, _v = u[0], v[0]\n",
    "        if not isinstance(_u, Iterable) or not isinstance(_v, Iterable):\n",
    "            return LONG_DISTANCE\n",
    "        unums = list(map(int, sum(map(num_pat.findall, _u), [])))\n",
    "        vnums = list(map(int, sum(map(num_pat.findall, _v), [])))\n",
    "        ulets = list(sum(map(let_pat.findall, _u), []))\n",
    "        vlets = list(sum(map(let_pat.findall, _v), []))\n",
    "        if not(unums and vnums):\n",
    "            if set(ulets).intersection(vlets):\n",
    "                return EQUAL\n",
    "            else:\n",
    "                return MEDIUM_DISTANCE\n",
    "        if u == v:\n",
    "            return EQUAL\n",
    "        if set(_u).intersection(set(_v)):\n",
    "            return LOW_DISTANCE\n",
    "        if not set(ulets).intersection(set(vlets)):\n",
    "            return MEDIUM_DISTANCE\n",
    "        else:\n",
    "            for p in _u:\n",
    "                for q in _v:\n",
    "                    try:\n",
    "                        pval = list(map(int, num_pat.findall(p)))[0]\n",
    "                        qval = list(map(int, num_pat.findall(q)))[0]\n",
    "                        if p[0] == q[0] and (abs(pval - qval) <= 2):\n",
    "                            return SMALL_DISTANCE\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "            return NORMAL_DISTANCE\n",
    "        return MEDIUM_DISTANCE\n",
    "    distances = pdist(df.Cabin.apply(lambda x: x.split() if not isinstance(x, float) else x).values[:, np.newaxis], cabin_distance)\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:, 'cabin_group'] = fcluster(complete(distances), SMALL_DISTANCE, criterion='distance')\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpipes.pfunc import *\n",
    "\n",
    "preprocessing_pipeline = (('add_groups', get_ticket_group, {}),\n",
    "                          ('add_isalone', get_is_alone, {}),\n",
    "                          ('add_titles', get_titles, {}),\n",
    "                          ('convert_fares', discretize_faries, {'ngroups': 4}),\n",
    "                          ('add_ticket_group', get_ticket_group, {}),\n",
    "                          ('fill_embarked', fill_na_simple, {'colnames': ('Embarked',),\n",
    "                                                             'methods': (lambda x: pd.Series(x).mode()[0],)}),\n",
    "                          ('add_family_name', get_family_name, {}),\n",
    "                          ('add_ages', estimate_age, {}),\n",
    "                          ('add_cabin_groups', get_cabin_groups, {}),\n",
    "                          ('drop_columns', drop_columns, {'colnames': ('Survived',\n",
    "                                                                       'PassengerId',\n",
    "                                                                       'SibSp',\n",
    "                                                                       'Parch',\n",
    "                                                                       'Ticket',\n",
    "                                                                       'Fare',\n",
    "                                                                       'family_name',\n",
    "                                                                       'Name',\n",
    "                                                                       \n",
    "                                                                       )}),\n",
    "                         )\n",
    "\n",
    "def process(pipeline, data):\n",
    "    data_ = data.copy()\n",
    "    for name, func, kwargs in pipeline:\n",
    "        print(\"=========== Step: %s ===========\" % name)\n",
    "        data_ = func(data_, **kwargs)\n",
    "        print(\"=\" * 40)\n",
    "    return data_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps (feature engeneering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Step: add_groups ===========\n",
      "========================================\n",
      "=========== Step: add_isalone ===========\n",
      "========================================\n",
      "=========== Step: add_titles ===========\n",
      "========================================\n",
      "=========== Step: convert_fares ===========\n",
      "========================================\n",
      "=========== Step: add_ticket_group ===========\n",
      "========================================\n",
      "=========== Step: fill_embarked ===========\n",
      "========================================\n",
      "=========== Step: add_family_name ===========\n",
      "========================================\n",
      "=========== Step: add_ages ===========\n",
      "========================================\n",
      "=========== Step: add_cabin_groups ===========\n",
      "========================================\n",
      "=========== Step: drop_columns ===========\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "processed  = process(preprocessing_pipeline, combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
