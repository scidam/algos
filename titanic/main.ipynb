{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining with Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some preprocessing of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is likely that `PassengerId` or `Ticket` number don't affect on passenger survillance. So, lets drop these columns at the beggining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self explanatory function, returns first name, title and the last name of a passenger\n",
    "def parse_name(s): \n",
    "    a, b = s.split(',')\n",
    "    family_name = a.strip()\n",
    "    title = b.split('.')[0].strip()\n",
    "    first_name = b.split('.')[1].split()[0].strip()\n",
    "    return (first_name, title, family_name)\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "class AbstractPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise Exception(\"Input data should be a DataFrame instance\")\n",
    "        return self\n",
    "\n",
    "\n",
    "class DropColumns(AbstractPreprocessor):\n",
    "    '''\n",
    "    Drops specified columns from a DataFrame.\n",
    "    \n",
    "    Input data assumed to be a DataFrame.\n",
    "    \n",
    "    Usage\n",
    "    -----\n",
    "        dropper = DropColumns(names=['PassengerId', 'Ticket'])\n",
    "        dropped_df = dropper.fit_transform(source_dataframe)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, names=[]):\n",
    "        self.names = names\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        filtered = [col for col in self.names if col in X.columns]\n",
    "        return X.drop(filtered, axis=1)\n",
    "\n",
    "class AddFirstNameColumn(AbstractPreprocessor):\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        result = X.copy()\n",
    "        result['first_name'] = X.loc[:, 'Name'].apply(lambda x: parse_name(x)[0].replace('(', '').replace(')', ''))\n",
    "        return result\n",
    "\n",
    "class AddFamilyNameColumn(AbstractPreprocessor):\n",
    "    def transform(self, X, y=None):\n",
    "        result = X.copy()\n",
    "        result['family_name'] = X.loc[:, 'Name'].apply(lambda x: parse_name(x)[-1])\n",
    "        return result\n",
    "                \n",
    "class AddTitleColumn(AbstractPreprocessor):\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        result = X.copy()\n",
    "        result['title'] = X.loc[:, 'Name'].apply(lambda x: parse_name(x)[1])\n",
    "        return result   \n",
    "\n",
    "class AddFamilySize(AbstractPreprocessor):\n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        _X['family_size'] = X['SibSp'] + X['Parch'] + 1\n",
    "        return _X\n",
    "\n",
    "class AddIsAlone(AbstractPreprocessor):\n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        _X['is_alone'] = 1\n",
    "        _X.loc[_X.family_size > 1,'is_alone'] = 0\n",
    "        return _X\n",
    "\n",
    "class OneHotEncodeAndDrop(AbstractPreprocessor):\n",
    "    \n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        aux = pd.get_dummies(X.loc[:, self.name], prefix=self.name)\n",
    "        return pd.concat([X.drop(self.name, axis=1), aux], axis=1)\n",
    "\n",
    "class LabelEncodeAndDrop(AbstractPreprocessor):\n",
    "    \n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "        self.enc = LabelEncoder()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.enc.fit(X.loc[:, self.name].values)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        new_values = self.enc.transform(_X.loc[:, self.name].values)\n",
    "        _X.loc[:, self.name] = new_values\n",
    "        return _X\n",
    "\n",
    "    \n",
    "class CombineCategoricalValues(AbstractPreprocessor):\n",
    "    def __init__(self, name=None, rule={'what': [], 'to': None}):\n",
    "        self.name = name\n",
    "        self.rule = rule\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        mask = X.loc[:, self.name].isin(self.rule['what'])\n",
    "        _X = X.copy()\n",
    "        _X.loc[:, self.name][mask] = self.rule['to']\n",
    "        return _X\n",
    "        \n",
    "class DropByValue(AbstractPreprocessor):\n",
    "    def __init__(self, name=None, value=None):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[X.loc[:, self.name] != self.value]\n",
    "    \n",
    "class GetCategoriesAndDrop(AbstractPreprocessor):\n",
    "    def __init__(self, name=None, bins=None):\n",
    "        self.name = name\n",
    "        self.bins = bins\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        aux = pd.cut(X.loc[:, self.name], bins=self.bins, labels=False)\n",
    "        return X.drop(self.name, axis=1).join(pd.get_dummies(aux, prefix=self.name))\n",
    "   \n",
    "    \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "class FillNaValues(AbstractPreprocessor):\n",
    "\n",
    "    def __init__(self, name=None, train=None, n_features=None,\n",
    "                 clf=RandomForestRegressor()):\n",
    "        self.train = train\n",
    "        self.name = name\n",
    "        self.clf = clf\n",
    "        self.n_features = n_features\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if self.name is None: \n",
    "            return X\n",
    "\n",
    "        if X.loc[:, self.name].isnull().sum() == 0:\n",
    "            return X\n",
    "        \n",
    "        _train = self.train.copy() if self.train is not None else X.copy()\n",
    "        null_mask = _train[self.name].isnull()\n",
    "        y = _train[self.name][~null_mask]\n",
    "        _train = _train.drop(self.name, axis=1)\n",
    "        \n",
    "        n_features = int(pd.np.ceil(X.shape[1] * 0.3) or self.n_features)\n",
    "        \n",
    "        encoders = dict()\n",
    "        for key in _train.columns.tolist():\n",
    "            if not pd.np.issubdtype(_train[key].dtype, pd.np.number):\n",
    "                _train.loc[_train[key].isnull(), key]  = 'N-a-N'\n",
    "                le = LabelEncoder()\n",
    "                _train[key] = le.fit_transform(_train[key])\n",
    "                encoders[key] = le\n",
    "            else:\n",
    "                if any(_train[key].isnull()):\n",
    "                    _train['%s_nan' % key] = 0.0\n",
    "                    _train.loc[_train[key].isnull(), '%s_nan' % key] = 1.0\n",
    "                    _train.loc[_train[key].isnull(), key] = _train.loc[~_train[key].isnull(), key].median()\n",
    "\n",
    "        self.clf.fit(_train[~null_mask], y)\n",
    "        \n",
    "        # dropping features\n",
    "        if hasattr(self.clf, 'feature_importances_'):\n",
    "            # drop columns and retrain classifier\n",
    "            indices = pd.np.argsort(self.clf.feature_importances_)[::-1]\n",
    "            features_to_drop = _train.columns[indices].values.tolist()[n_features:]\n",
    "            self.clf.fit(_train.drop(features_to_drop, axis=1)[~null_mask], y)\n",
    "        else:\n",
    "            features_to_drop = []\n",
    "            \n",
    "        _X = X.copy()\n",
    "        for key in _train.columns:\n",
    "            if key not in _X.columns:\n",
    "                _X.loc[:, key] = 0.0\n",
    "        _X = _X[_train.columns]\n",
    "        for key in encoders.keys():\n",
    "            if not pd.np.issubdtype(_X[key].dtype, pd.np.number):\n",
    "                _X.loc[_X[key].isnull(), key]  = 'N-a-N'\n",
    "                _X[key] = encoders[key].transform(_X[key])\n",
    "            else:\n",
    "                if any(_X[key].isnull()):\n",
    "                    _X['%s_nan' % key] = 0.0\n",
    "                    _X.loc[_X[key].isnull(), '%s_nan' % key] = 1.0\n",
    "                    _X.loc[_X[key].isnull(), key] = X.loc[~_X[key].isnull(), key].median()\n",
    "        \n",
    "        na_replacements = self.clf.predict(_X.drop(features_to_drop, axis=1)[null_mask])\n",
    "        result = X.copy()\n",
    "        result.loc[null_mask, self.name] = na_replacements\n",
    "        return result\n",
    "\n",
    "class FillNaEmbarkedSimple(AbstractPreprocessor):\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        _X['Embarked'] = _X['Embarked'].fillna(_X.Embarked.dropna().mode()[0])\n",
    "        return _X\n",
    "    \n",
    "class DropRows(AbstractPreprocessor):\n",
    "\n",
    "    def __init__(self, condition=None):\n",
    "        self.condition = condition #condition depends on (X, y) and \n",
    "        # returns boolean array of the same length as X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def trasform(self, X, y=None):\n",
    "        if self.condition is not None:\n",
    "            return X[self.condition(X, y)]\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "\n",
    "class ShowDataHead(AbstractPreprocessor):\n",
    "    def fit(self, X, y=None):\n",
    "        display(HTML(X.head().to_html()))\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps (feature engeneering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/ipykernel_launcher.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "preprocessing_steps = [('drop_columns', DropColumns(names=['Ticket', 'PassengerId', 'Cabin', 'Survived'])),\n",
    "                       ('add_title', AddTitleColumn()),\n",
    "                       ('add_first_name', AddFirstNameColumn()),\n",
    "                       ('add_family_name', AddFamilyNameColumn()),\n",
    "                       ('add_family_size', AddFamilySize()),\n",
    "                       ('drop_name', DropColumns(names=['Name'])),\n",
    "                       ('encode_sex', LabelEncodeAndDrop(name='Sex')),\n",
    "                       ('fillna_embarked', FillNaEmbarkedSimple()),\n",
    "                       ('encode_embarked', LabelEncodeAndDrop(name='Embarked')),\n",
    "                       \n",
    "                       # predicting nan-values\n",
    "                       ('predict_fare', FillNaValues(name='Fare')),\n",
    "                       ('predict_age', FillNaValues(name='Age')),\n",
    "                     \n",
    "                       # combine & encode titles\n",
    "                       ('combine_title_Mrs', CombineCategoricalValues(name='title', rule={'what': ['Dona', 'Lady', 'Mme', 'the Countess'], 'to': 'Mrs'})),\n",
    "                       ('combine_title_Mr', CombineCategoricalValues(name='title', rule={'what': ['Master', 'Jonkheer', 'Major', 'Col', 'Sir', 'Rev', 'Don', 'Capt', 'Dr'], 'to': 'Mr'})),\n",
    "                       ('combine_title_Miss', CombineCategoricalValues(name='title', rule={'what': ['Mlle', 'Ms'], 'to': 'Miss'})),\n",
    "                       ('encode_title', LabelEncodeAndDrop(name='title')),\n",
    "                       \n",
    "                       #\n",
    "                       ('add_is_alone', AddIsAlone()),\n",
    "                       \n",
    "                       #drop first name, family name\n",
    "                       ('drop_last', DropColumns(names=['first_name','family_name', 'family_size'])),\n",
    "                      ]\n",
    "\n",
    "preprocessing_pipeline = Pipeline(steps=preprocessing_steps)\n",
    "combined_processed = preprocessing_pipeline.fit_transform(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It seems that all is ready. Lets make a classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = combined_processed.iloc[:train.shape[0]]\n",
    "test_processed = combined_processed.iloc[train.shape[0]:]\n",
    "y = train.Survived.values.astype(int)\n",
    "X = train_processed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid searching for  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    1.9s finished\n",
      "/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is  0.7810757177038836\n",
      "Performing grid searching for  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   28.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is  0.8055130183681055\n",
      "Performing grid searching for  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is  0.7121433441254045\n",
      "Performing grid searching for  GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best score is  0.7785814862497952\n",
      "Performing grid searching for  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:   51.2s finished\n",
      "/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is  0.8092941565353926\n",
      "Performing grid searching for  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 443 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:   21.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score is  0.813375361346313\n",
      "Performing grid searching for  LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001)\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best score is  0.7737764666994019\n",
      "Performing grid searching for  QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best score is  0.7984102358234704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "classifiers = [{'clf': LogisticRegression(), 'params': {'penalty':('l1', 'l2'), 'C': pd.np.linspace(1.e-6, 3, 20)}}, \n",
    "               {'clf': RandomForestClassifier(), 'params':{'n_estimators':[10, 50, 100, 500], 'max_depth': [2, 3, 5, 7, 11], \n",
    "                                                          'max_features': ['auto', 'log2', 'sqrt']}},\n",
    "               {'clf': KNeighborsClassifier(), 'params': {'n_neighbors': [1, 3, 5, 7], 'p': [1, 2]}},\n",
    "               {'clf': GaussianNB(), 'params': {'priors': [[0.7, 0.3], [0.8, 0.2]]}},\n",
    "               {'clf': AdaBoostClassifier(), 'params': {'base_estimator': (DecisionTreeClassifier(max_depth=1),\n",
    "                                                                           DecisionTreeClassifier(max_depth=2),\n",
    "                                                                           DecisionTreeClassifier(max_depth=3),\n",
    "                                                                           DecisionTreeClassifier(max_depth=5),\n",
    "                                                                           DecisionTreeClassifier(max_depth=7)),\n",
    "                                                       'n_estimators': [20, 50, 100, 200],\n",
    "                                                       'algorithm': ['SAMME', 'SAMME.R'],\n",
    "                                                       'learning_rate': (2.0, 1.0, 0.5, 0.05)}},\n",
    "               {'clf': GradientBoostingClassifier(), 'params': {'loss': ('deviance', 'exponential'),\n",
    "                                                                'learning_rate': (0.5, 0.1, 0.05, 0.01),\n",
    "                                                                'n_estimators': [20, 50, 100, 200],\n",
    "                                                                'subsample': [1.0, 0.9],\n",
    "                                                                'max_depth': [1,2,3]}},\n",
    "               {'clf': LinearDiscriminantAnalysis(), 'params': {'priors': [[0.68, 0.32]], 'n_components': [2, 4, 6]}},\n",
    "               {'clf': QuadraticDiscriminantAnalysis(), 'params': {'priors': [[0.68, 0.32]]}},\n",
    "               #{'clf': SVC(gamma='scale'), 'params': {'kernel':('rbf', 'linear'), 'C': [1.0, 10.0, 100.0, 1000.0]}},\n",
    "              ]\n",
    "results = dict()\n",
    "for c in classifiers:\n",
    "    print(\"Performing grid searching for \", c['clf'])\n",
    "    clf = GridSearchCV(c['clf'], c['params'], cv=5, scoring='balanced_accuracy', verbose=True, n_jobs=-1)\n",
    "    clf.fit(X, y)\n",
    "    results[c['clf']] = clf\n",
    "    print(\"Best score is \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated score is  0.8317319260015891\n"
     ]
    }
   ],
   "source": [
    "best_classifiers = list(map(lambda x: (x[0], x[1]), sorted([(k.__class__.__name__, v.best_estimator_, v) for k, v in results.items()], key=lambda x: x[-1].best_score_, reverse=True)[:3]))\n",
    "best = VotingClassifier(best_classifiers, n_jobs=-1)\n",
    "best.fit(X, y)\n",
    "print(\"Estimated score is \", cross_val_score(best, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": best.predict(test_processed.values).astype(int)\n",
    "    })\n",
    "submission.to_csv('./output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1288</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>1296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "5            897         0\n",
       "6            898         0\n",
       "7            899         0\n",
       "8            900         1\n",
       "9            901         0\n",
       "10           902         0\n",
       "11           903         0\n",
       "12           904         1\n",
       "13           905         0\n",
       "14           906         1\n",
       "15           907         1\n",
       "16           908         0\n",
       "17           909         0\n",
       "18           910         1\n",
       "19           911         0\n",
       "20           912         0\n",
       "21           913         1\n",
       "22           914         1\n",
       "23           915         0\n",
       "24           916         1\n",
       "25           917         0\n",
       "26           918         1\n",
       "27           919         0\n",
       "28           920         1\n",
       "29           921         0\n",
       "..           ...       ...\n",
       "388         1280         0\n",
       "389         1281         0\n",
       "390         1282         0\n",
       "391         1283         1\n",
       "392         1284         0\n",
       "393         1285         0\n",
       "394         1286         0\n",
       "395         1287         1\n",
       "396         1288         0\n",
       "397         1289         1\n",
       "398         1290         0\n",
       "399         1291         0\n",
       "400         1292         1\n",
       "401         1293         0\n",
       "402         1294         1\n",
       "403         1295         0\n",
       "404         1296         0\n",
       "405         1297         0\n",
       "406         1298         0\n",
       "407         1299         0\n",
       "408         1300         1\n",
       "409         1301         1\n",
       "410         1302         1\n",
       "411         1303         1\n",
       "412         1304         1\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
