{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining with Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some preprocessing of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is likely that `PassengerId` or `Ticket` number don't affect on passenger survillance. So, lets drop these columns at the beggining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self explanatory function, returns first name, title and the last name of a passenger\n",
    "def parse_name(s): \n",
    "    a, b = s.split(',')\n",
    "    family_name = a.strip()\n",
    "    title = b.split('.')[0].strip()\n",
    "    first_name = b.split('.')[1].split()[0].strip()\n",
    "    return (first_name, title, family_name)\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "class AbstractPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise Exception(\"Input data should be a DataFrame instance\")\n",
    "        return self\n",
    "\n",
    "\n",
    "class DropColumns(AbstractPreprocessor):\n",
    "    '''\n",
    "    Drops specified columns from a DataFrame.\n",
    "    \n",
    "    Input data assumed to be a DataFrame.\n",
    "    \n",
    "    Usage\n",
    "    -----\n",
    "        dropper = DropColumns(names=['PassengerId', 'Ticket'])\n",
    "        dropped_df = dropper.fit_transform(source_dataframe)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, names=[]):\n",
    "        self.names = names\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        filtered = [col for col in self.names if col in X.columns]\n",
    "        return X.drop(filtered, axis=1)\n",
    "\n",
    "class AddFirstNameColumn(AbstractPreprocessor):\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        result = X.copy()\n",
    "        result['first_name'] = X.loc[:, 'Name'].apply(lambda x: parse_name(x)[0].replace('(', '').replace(')', ''))\n",
    "        return result\n",
    "\n",
    "class AddFamilyNameColumn(AbstractPreprocessor):\n",
    "    def transform(self, X, y=None):\n",
    "        result = X.copy()\n",
    "        result['family_name'] = X.loc[:, 'Name'].apply(lambda x: parse_name(x)[-1])\n",
    "        return result\n",
    "                \n",
    "class AddTitleColumn(AbstractPreprocessor):\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        result = X.copy()\n",
    "        result['title'] = X.loc[:, 'Name'].apply(lambda x: parse_name(x)[1])\n",
    "        return result   \n",
    "\n",
    "class AddFamilySize(AbstractPreprocessor):\n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        _X['family_size'] = X['SibSp'] + X['Parch'] + 1\n",
    "        return _X\n",
    "\n",
    "class AddIsAlone(AbstractPreprocessor):\n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        _X['is_alone'] = 1\n",
    "        _X.loc[_X.family_size > 1,'is_alone'] = 0\n",
    "        return _X\n",
    "\n",
    "class OneHotEncodeAndDrop(AbstractPreprocessor):\n",
    "    \n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        aux = pd.get_dummies(X.loc[:, self.name], prefix=self.name)\n",
    "        return pd.concat([X.drop(self.name, axis=1), aux], axis=1)\n",
    "\n",
    "class LabelEncodeAndDrop(AbstractPreprocessor):\n",
    "    \n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "        self.enc = LabelEncoder()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.enc.fit(X.loc[:, self.name].values)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        new_values = self.enc.transform(_X.loc[:, self.name].values)\n",
    "        _X.loc[:, self.name] = new_values\n",
    "        return _X\n",
    "\n",
    "class SelectFeatures(AbstractPreprocessor):\n",
    "    \n",
    "    def __init__(self, k, n):\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        _ = [int(x) for x in bin(self.k)[2:]]\n",
    "        _ = [0] * (self.n - len(_)) + _\n",
    "        return X.iloc[:, [j for j in range(self.n) if _[j]]]\n",
    "    \n",
    "    \n",
    "class CombineCategoricalValues(AbstractPreprocessor):\n",
    "    def __init__(self, name=None, rule={'what': [], 'to': None}):\n",
    "        self.name = name\n",
    "        self.rule = rule\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        mask = X.loc[:, self.name].isin(self.rule['what'])\n",
    "        _X = X.copy()\n",
    "        _X.loc[:, self.name][mask] = self.rule['to']\n",
    "        return _X\n",
    "        \n",
    "class DropByValue(AbstractPreprocessor):\n",
    "    def __init__(self, name=None, value=None):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[X.loc[:, self.name] != self.value]\n",
    "    \n",
    "class GetCategoriesAndDrop(AbstractPreprocessor):\n",
    "    def __init__(self, name=None, bins=None):\n",
    "        self.name = name\n",
    "        self.bins = bins\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.bins is not None and hasattr(X, self.name):\n",
    "            aux = pd.qcut(X.loc[:, self.name], q=self.bins, labels=False)\n",
    "            _X = X.drop(self.name, axis=1)\n",
    "            _X[self.name] = aux\n",
    "            return _X\n",
    "        else:\n",
    "            return X\n",
    "   \n",
    "    \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "class FillNaValues(AbstractPreprocessor):\n",
    "\n",
    "    def __init__(self, name=None, train=None, n_features=None,\n",
    "                 clf=RandomForestRegressor()):\n",
    "        self.train = train\n",
    "        self.name = name\n",
    "        self.clf = clf\n",
    "        self.n_features = n_features\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if self.name is None: \n",
    "            return X\n",
    "\n",
    "        if X.loc[:, self.name].isnull().sum() == 0:\n",
    "            return X\n",
    "        \n",
    "        _train = self.train.copy() if self.train is not None else X.copy()\n",
    "        null_mask = _train[self.name].isnull()\n",
    "        y = _train[self.name][~null_mask]\n",
    "        _train = _train.drop(self.name, axis=1)\n",
    "        \n",
    "        n_features = int(pd.np.ceil(X.shape[1] * 0.3) or self.n_features)\n",
    "        \n",
    "        encoders = dict()\n",
    "        for key in _train.columns.tolist():\n",
    "            if not pd.np.issubdtype(_train[key].dtype, pd.np.number):\n",
    "                _train.loc[_train[key].isnull(), key]  = 'N-a-N'\n",
    "                le = LabelEncoder()\n",
    "                _train[key] = le.fit_transform(_train[key])\n",
    "                encoders[key] = le\n",
    "            else:\n",
    "                if any(_train[key].isnull()):\n",
    "                    _train['%s_nan' % key] = 0.0\n",
    "                    _train.loc[_train[key].isnull(), '%s_nan' % key] = 1.0\n",
    "                    _train.loc[_train[key].isnull(), key] = _train.loc[~_train[key].isnull(), key].median()\n",
    "\n",
    "        self.clf.fit(_train[~null_mask], y)\n",
    "        \n",
    "        # dropping features\n",
    "        if hasattr(self.clf, 'feature_importances_'):\n",
    "            # drop columns and retrain classifier\n",
    "            indices = pd.np.argsort(self.clf.feature_importances_)[::-1]\n",
    "            features_to_drop = _train.columns[indices].values.tolist()[n_features:]\n",
    "            self.clf.fit(_train.drop(features_to_drop, axis=1)[~null_mask], y)\n",
    "        else:\n",
    "            features_to_drop = []\n",
    "            \n",
    "        _X = X.copy()\n",
    "        for key in _train.columns:\n",
    "            if key not in _X.columns:\n",
    "                _X.loc[:, key] = 0.0\n",
    "        _X = _X[_train.columns]\n",
    "        for key in encoders.keys():\n",
    "            if not pd.np.issubdtype(_X[key].dtype, pd.np.number):\n",
    "                _X.loc[_X[key].isnull(), key]  = 'N-a-N'\n",
    "                _X[key] = encoders[key].transform(_X[key])\n",
    "            else:\n",
    "                if any(_X[key].isnull()):\n",
    "                    _X['%s_nan' % key] = 0.0\n",
    "                    _X.loc[_X[key].isnull(), '%s_nan' % key] = 1.0\n",
    "                    _X.loc[_X[key].isnull(), key] = X.loc[~_X[key].isnull(), key].median()\n",
    "        \n",
    "        na_replacements = self.clf.predict(_X.drop(features_to_drop, axis=1)[null_mask])\n",
    "        result = X.copy()\n",
    "        result.loc[null_mask, self.name] = na_replacements\n",
    "        return result\n",
    "\n",
    "\n",
    "class FillNaSimple(AbstractPreprocessor):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        _X = X.copy()\n",
    "        if hasattr(_X, self.name):\n",
    "            _X.loc[:, self.name] = _X.loc[:, self.name].fillna(_X.loc[:, self.name].dropna().mode()[0])\n",
    "        return _X\n",
    "    \n",
    "class DropRows(AbstractPreprocessor):\n",
    "\n",
    "    def __init__(self, condition=None):\n",
    "        self.condition = condition #condition depends on (X, y) and \n",
    "        # returns boolean array of the same length as X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def trasform(self, X, y=None):\n",
    "        if self.condition is not None:\n",
    "            return X[self.condition(X, y)]\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "\n",
    "class ShowDataHead(AbstractPreprocessor):\n",
    "    def fit(self, X, y=None):\n",
    "        display(HTML(X.head().to_html()))\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps (feature engeneering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitry/.pyenv/versions/3.5.4/envs/sci/lib/python3.5/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>title</th>\n",
       "      <th>family_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "preprocessing_steps = [('drop_columns', DropColumns(names=['Ticket', 'PassengerId', 'Cabin', 'Survived'])),\n",
    "                       ('add_title', AddTitleColumn()),\n",
    "                       # ('add_first_name', AddFirstNameColumn()),\n",
    "                       #('add_family_name', AddFamilyNameColumn()),\n",
    "                       ('add_family_size', AddFamilySize()),\n",
    "                       ('encode_sex', LabelEncodeAndDrop(name='Sex')),\n",
    "                       ('fillna_embarked', FillNaSimple(name='Embarked')),\n",
    "                       #('combine_embarked', CombineCategoricalValues(name='Embarked', rule={'what': ['C', 'Q'], 'to': 'Q'})),\n",
    "                       ('encode_embarked', LabelEncodeAndDrop(name='Embarked')),\n",
    "                       \n",
    "                       # predicting nan-values\n",
    "                       ('predict_fare', FillNaSimple(name='Fare')),\n",
    "                       ('predict_age', FillNaSimple(name='Age')),\n",
    "                    #  ('cat_ages', GetCategoriesAndDrop(name='Age', bins=[0, 0.3, 0.6, 1.0])),\n",
    "                    #  ('cat_fares', GetCategoriesAndDrop(name='Fare', bins=[0, 0.3, 0.6, 1.0])),\n",
    "                       \n",
    "                       # combine & encode titles\n",
    "                       #('combine_title_Mrs', CombineCategoricalValues(name='title', rule={'what': ['Dona', 'Mme', 'the Countess'], 'to': 'Mrs'})),\n",
    "                       #('combine_title_Mr', CombineCategoricalValues(name='title', rule={'what': ['Jonkheer', 'Major', 'Col', 'Rev', 'Mr'], 'to': 'Mr1'})),\n",
    "                       #('combine_title_Mr', CombineCategoricalValues(name='title', rule={'what': ['Master', 'Sir', 'Don', 'Dr'], 'to': 'Mr2'})),\n",
    "                       #('combine_title_Miss', CombineCategoricalValues(name='title', rule={'what': ['Mlle','Lady','Ms'], 'to': 'Miss'})),\n",
    "                       ('combine_title_rare', CombineCategoricalValues(name='title', rule={'what': ['Rev', 'Dr', 'Col', 'Ms', 'Mlle', 'Major', 'Sir', 'Mme','Lady','Capt','the Countess','Jonkheer','Don','Dona'], 'to': 'rare'})),\n",
    "                       ('encode_title', LabelEncodeAndDrop(name='title')),\n",
    "                       \n",
    "                       #\n",
    "                       #('add_is_alone', AddIsAlone()),\n",
    "                       \n",
    "                       # last one-hots... \n",
    "                       #('encode_fare', OneHotEncodeAndDrop(name='Fare')),\n",
    "                       #('encode_age', OneHotEncodeAndDrop(name='Age')),\n",
    "                       #('encode_Pclass', OneHotEncodeAndDrop(name='Pclass')),\n",
    "                       #('combine_fsize', CombineCategoricalValues(name='family_size', rule={'what': ['5','6', '7','8','9','10','11'], 'to': '5'})),\n",
    "                       #('encode_fsize', OneHotEncodeAndDrop(name='family_size')),\n",
    "                       \n",
    "                       #drop first name, family name\n",
    "                       ('drop_last', DropColumns(names=['first_name','family_name', 'Name'])),\n",
    "                       ('show_data', ShowDataHead())\n",
    "                      ]\n",
    "\n",
    "preprocessing_pipeline = Pipeline(steps=preprocessing_steps)\n",
    "combined_processed = preprocessing_pipeline.fit_transform(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It seems that all is ready. Lets make a classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = combined_processed.iloc[:train.shape[0]]\n",
    "test_processed = combined_processed.iloc[train.shape[0]:]\n",
    "y = train.Survived.values.astype(int)\n",
    "X = train_processed.values\n",
    "N_FEATURES = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features are:  Index(['title'], dtype='object')\n",
      "Performing grid searching for  RandomForestClassifier 1\n",
      "Best score is  0.7654107947464289\n",
      "Performing grid searching for  AdaBoostClassifier 1\n",
      "Best score is  0.7654107947464289\n",
      "Performing grid searching for  GradientBoostingClassifier 1\n",
      "Best score is  0.7654107947464289\n"
     ]
    }
   ],
   "source": [
    "classifiers = [#{'clf': LogisticRegression(), 'params': {'penalty':('l1', 'l2'), 'C': pd.np.linspace(1.e-6, 3, 20)}}, \n",
    "               {'clf': RandomForestClassifier(), 'params':{'n_estimators':[10, 50, 100, 500], 'max_depth': [2, 3, 5, 7, 11, None]}},\n",
    "               #{'clf': KNeighborsClassifier(), 'params': {'n_neighbors': [1, 3, 5, 7], 'p': [1, 2]}},\n",
    "               #{'clf': GaussianNB(), 'params': {'priors': [[0.7, 0.3], [0.8, 0.2]]}},\n",
    "               {'clf': AdaBoostClassifier(), 'params': {'base_estimator': (DecisionTreeClassifier(max_depth=1),\n",
    "                                                                           ExtraTreeClassifier(max_depth=3),\n",
    "                                                                           ExtraTreeClassifier(max_depth=1),\n",
    "                                                                           ExtraTreeClassifier(max_depth=5),),\n",
    "                                                       'n_estimators': [20, 50, 100, 200, 500],\n",
    "                                                       'algorithm': ['SAMME', 'SAMME.R'],\n",
    "                                                       'learning_rate': (2.0, 1.0, 0.5, 0.05)}},\n",
    "               {'clf': GradientBoostingClassifier(), 'params': {'loss': ('deviance', 'exponential'),\n",
    "                                                                'n_estimators': [20, 50, 100, 200, 400],\n",
    "                                                                'subsample': [1.0, 0.9],\n",
    "                                                                'max_depth': [1,2,3]}},\n",
    "               #{'clf': LinearDiscriminantAnalysis(), 'params': {'priors': [[0.68, 0.32]], 'n_components': [2, 4, 6]}},\n",
    "               #{'clf': QuadraticDiscriminantAnalysis(), 'params': {'priors': [[0.68, 0.32]]}},\n",
    "               #{'clf': SVC(gamma='scale'), 'params': {'kernel':('rbf', 'linear'), 'C': [1.0, 10.0, 100.0, 1000.0]}},\n",
    "              ]\n",
    "results = dict()\n",
    "for j in range(2, N_FEATURES**2):\n",
    "    aux = SelectFeatures(j, N_FEATURES).transform(train_processed)\n",
    "    print(\"Selected features are: \", aux.columns)\n",
    "    X = aux.values\n",
    "    for c in classifiers:\n",
    "        print(\"Performing grid searching for \", c['clf'].__class__.__name__, j)\n",
    "        clf = GridSearchCV(c['clf'], c['params'], cv=3, scoring='balanced_accuracy', verbose=False, n_jobs=-1);\n",
    "        clf.fit(X, y)\n",
    "        results[c['clf'].__class__.__name__ + '_' + str(j)] = clf\n",
    "        print(\"Best score is \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated score is  0.667945734908346\n"
     ]
    }
   ],
   "source": [
    "# Select the best classifier and use it\n",
    "best_classifiers = list(sorted([(k, v.best_estimator_, v.best_params_, v) for k, v in results.items()],\n",
    "                          key=lambda x: x[-1].best_score_, reverse=True))[:3]\n",
    "best_classifiers = [(est.__class__.__name__ + str(ind), est) for ind, est in enumerate(map(lambda x: make_pipeline(SelectFeatures(int(x[0].split('_')[-1]), N_FEATURES), x[1].__class__(**x[2])), best_classifiers))]\n",
    "best = VotingClassifier(best_classifiers, n_jobs=1)\n",
    "best.fit(train_processed, y)\n",
    "print(\"Estimated score is \", cross_val_score(best, train_processed, y, cv=3).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": best.predict(test_processed).astype(int)\n",
    "    })\n",
    "submission.to_csv('./output/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
