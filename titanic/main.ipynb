{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining with Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "combined = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_name(s): \n",
    "    a, b = s.split(',')\n",
    "    family_name = a.strip()\n",
    "    title = b.split('.')[0].strip()\n",
    "    first_name = b.split('.')[1].split()[0].strip()\n",
    "    return (first_name.replace('(', '').replace(')', ''), title, family_name)\n",
    "\n",
    "def parse_cabin_letter(column):\n",
    "    counts = column.value_counts()\n",
    "    letter_pat = re.compile('([A-Za-z])\\d?')\n",
    "    return list(map(lambda x: letter_pat.findall(x)[0] if letter_pat.findall(x) else pd.np.nan, column.values.tolist()))\n",
    "\n",
    "def parse_ticket_number(column):\n",
    "    number_pat = re.compile('\\d{3,}')\n",
    "    numbers = map(lambda x: number_pat.findall(x)[0] if number_pat.findall(x) else pd.np.nan, column)\n",
    "    return pd.Series(numbers)\n",
    "\n",
    "\n",
    "def get_friendship_group(df):\n",
    "    friendship_group_counter = 0\n",
    "    if 'family_name' not in df.columns:\n",
    "        family_names = pd.Series(map(lambda x: parse_name(x)[-1], df.Name))\n",
    "    else:\n",
    "        family_names = df.family_name\n",
    "    cabins = pd.Series(map(parse_cabin_letter, df.Cabin))\n",
    "    ticket_grouping = []\n",
    "    for family, count in family_names.value_counts().items():\n",
    "        family_mask = family_names == family\n",
    "        \n",
    "        if count == 1:\n",
    "            ticket_grouping.append(friendship_group_counter)\n",
    "            friendship_group_counter += 1\n",
    "            continue\n",
    "    \n",
    "def get_ticket_group(df):\n",
    "    grouped = df.Ticket.groupby(parse_ticket_number(combined.Ticket))\n",
    "    groups = grouped.apply(lambda x: x.iloc[0])\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:, 'ticket_group'] = groups\n",
    "    return df_\n",
    "\n",
    "def get_cabin_letter(df):\n",
    "    df_ = df.copy()\n",
    "    cabins = parse_cabin_letter(df.Cabin)\n",
    "    df_.loc[:, 'cabin_na'] = cabins.isna()\n",
    "    df_.loc[:, 'cabin'] = cabins\n",
    "    return df_\n",
    "\n",
    "def get_is_alone(df):\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:, 'is_alone'] = df.loc[:, 'Parch'] + df.loc[:, 'SibSp'] + 1\n",
    "    return df_\n",
    "\n",
    "def get_titles(df):\n",
    "    df_ = df.copy()\n",
    "    titles = pd.Series(map(lambda x: parse_name(x)[1], df.Name))\n",
    "    df_.loc[:, 'title'] = titles\n",
    "    return df_\n",
    "\n",
    "def discretize_faries(df, ngroups=3):\n",
    "    df_ = df.copy()\n",
    "    df_.loc[:, 'fares'] = pd.cut(df_.loc['Fare'], ngroups, labels=False)\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1241\n",
       "1.0      50\n",
       "2.0      13\n",
       "3.0       4\n",
       "Name: Fare, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(combined.Fare, bins=4, labels=False).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlpipes.pfunc import *\n",
    "\n",
    "\n",
    "preprocessing_pipeline = (('add_groups', get_ticket_group, kwargs={}),\n",
    "                          ('add_cabins', get_cabin_letter, kwargs={}),\n",
    "                          ('add_isalone', get_is_alone, kwargs={}),\n",
    "                          ('add_titles', get_titles, kwargs={}),\n",
    "                          ('convert_fares', discretize_faries, kwargs={'ngroups': 3})\n",
    "                \n",
    "                          )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "class AbstractPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise Exception(\"Input data should be a DataFrame instance\")\n",
    "        return self\n",
    "\n",
    "class SelectFeatures(AbstractPreprocessor):\n",
    "    \n",
    "    def __init__(self, k, n):\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        _ = [int(x) for x in bin(self.k)[2:]]\n",
    "        _ = [0] * (self.n - len(_)) + _\n",
    "        return X.iloc[:, [j for j in range(self.n) if _[j]]]\n",
    "  \n",
    "        \n",
    "\n",
    "class GetCategoriesAndDrop(AbstractPreprocessor):\n",
    "    def __init__(self, name=None, bins=None):\n",
    "        self.name = name\n",
    "        self.bins = bins\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.bins is not None and hasattr(X, self.name):\n",
    "            aux = pd.qcut(X.loc[:, self.name], q=self.bins, labels=False)\n",
    "            _X = X.drop(self.name, axis=1)\n",
    "            _X[self.name] = aux\n",
    "            return _X\n",
    "        else:\n",
    "            return X\n",
    "   \n",
    "    \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "class FillNaValues(AbstractPreprocessor):\n",
    "\n",
    "    def __init__(self, name=None, train=None, n_features=None,\n",
    "                 clf=RandomForestRegressor()):\n",
    "        self.train = train\n",
    "        self.name = name\n",
    "        self.clf = clf\n",
    "        self.n_features = n_features\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        if self.name is None: \n",
    "            return X\n",
    "\n",
    "        if X.loc[:, self.name].isnull().sum() == 0:\n",
    "            return X\n",
    "        \n",
    "        _train = self.train.copy() if self.train is not None else X.copy()\n",
    "        null_mask = _train[self.name].isnull()\n",
    "        y = _train[self.name][~null_mask]\n",
    "        _train = _train.drop(self.name, axis=1)\n",
    "        \n",
    "        n_features = int(pd.np.ceil(X.shape[1] * 0.3) or self.n_features)\n",
    "        \n",
    "        encoders = dict()\n",
    "        for key in _train.columns.tolist():\n",
    "            if not pd.np.issubdtype(_train[key].dtype, pd.np.number):\n",
    "                _train.loc[_train[key].isnull(), key]  = 'N-a-N'\n",
    "                le = LabelEncoder()\n",
    "                _train[key] = le.fit_transform(_train[key])\n",
    "                encoders[key] = le\n",
    "            else:\n",
    "                if any(_train[key].isnull()):\n",
    "                    _train['%s_nan' % key] = 0.0\n",
    "                    _train.loc[_train[key].isnull(), '%s_nan' % key] = 1.0\n",
    "                    _train.loc[_train[key].isnull(), key] = _train.loc[~_train[key].isnull(), key].median()\n",
    "\n",
    "        self.clf.fit(_train[~null_mask], y)\n",
    "        \n",
    "        # dropping features\n",
    "        if hasattr(self.clf, 'feature_importances_'):\n",
    "            # drop columns and retrain classifier\n",
    "            indices = pd.np.argsort(self.clf.feature_importances_)[::-1]\n",
    "            features_to_drop = _train.columns[indices].values.tolist()[n_features:]\n",
    "            self.clf.fit(_train.drop(features_to_drop, axis=1)[~null_mask], y)\n",
    "        else:\n",
    "            features_to_drop = []\n",
    "            \n",
    "        _X = X.copy()\n",
    "        for key in _train.columns:\n",
    "            if key not in _X.columns:\n",
    "                _X.loc[:, key] = 0.0\n",
    "        _X = _X[_train.columns]\n",
    "        for key in encoders.keys():\n",
    "            if not pd.np.issubdtype(_X[key].dtype, pd.np.number):\n",
    "                _X.loc[_X[key].isnull(), key]  = 'N-a-N'\n",
    "                _X[key] = encoders[key].transform(_X[key])\n",
    "            else:\n",
    "                if any(_X[key].isnull()):\n",
    "                    _X['%s_nan' % key] = 0.0\n",
    "                    _X.loc[_X[key].isnull(), '%s_nan' % key] = 1.0\n",
    "                    _X.loc[_X[key].isnull(), key] = X.loc[~_X[key].isnull(), key].median()\n",
    "        \n",
    "        na_replacements = self.clf.predict(_X.drop(features_to_drop, axis=1)[null_mask])\n",
    "        result = X.copy()\n",
    "        result.loc[null_mask, self.name] = na_replacements\n",
    "        return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps (feature engeneering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "preprocessing_steps = [('drop_columns', DropColumns(names=['Ticket', 'PassengerId', 'Cabin', 'Survived'])),\n",
    "                       ('add_title', AddTitleColumn()),\n",
    "                       # ('add_first_name', AddFirstNameColumn()),\n",
    "                       #('add_family_name', AddFamilyNameColumn()),\n",
    "                       ('add_family_size', AddFamilySize()),\n",
    "                       ('encode_sex', LabelEncodeAndDrop(name='Sex')),\n",
    "                       ('fillna_embarked', FillNaSimple(name='Embarked')),\n",
    "                       #('combine_embarked', CombineCategoricalValues(name='Embarked', rule={'what': ['C', 'Q'], 'to': 'Q'})),\n",
    "                       ('encode_embarked', LabelEncodeAndDrop(name='Embarked')),\n",
    "                       \n",
    "                       # predicting nan-values\n",
    "                       ('predict_fare', FillNaSimple(name='Fare')),\n",
    "                       ('predict_age', FillNaSimple(name='Age')),\n",
    "                    #  ('cat_ages', GetCategoriesAndDrop(name='Age', bins=[0, 0.3, 0.6, 1.0])),\n",
    "                    #  ('cat_fares', GetCategoriesAndDrop(name='Fare', bins=[0, 0.3, 0.6, 1.0])),\n",
    "                       \n",
    "                       # combine & encode titles\n",
    "                       #('combine_title_Mrs', CombineCategoricalValues(name='title', rule={'what': ['Dona', 'Mme', 'the Countess'], 'to': 'Mrs'})),\n",
    "                       #('combine_title_Mr', CombineCategoricalValues(name='title', rule={'what': ['Jonkheer', 'Major', 'Col', 'Rev', 'Mr'], 'to': 'Mr1'})),\n",
    "                       #('combine_title_Mr', CombineCategoricalValues(name='title', rule={'what': ['Master', 'Sir', 'Don', 'Dr'], 'to': 'Mr2'})),\n",
    "                       #('combine_title_Miss', CombineCategoricalValues(name='title', rule={'what': ['Mlle','Lady','Ms'], 'to': 'Miss'})),\n",
    "                       ('combine_title_rare', CombineCategoricalValues(name='title', rule={'what': ['Rev', 'Dr', 'Col', 'Ms', 'Mlle', 'Major', 'Sir', 'Mme','Lady','Capt','the Countess','Jonkheer','Don','Dona'], 'to': 'rare'})),\n",
    "                       ('encode_title', LabelEncodeAndDrop(name='title')),\n",
    "                       \n",
    "                       #\n",
    "                       #('add_is_alone', AddIsAlone()),\n",
    "                       \n",
    "                       # last one-hots... \n",
    "                       #('encode_fare', OneHotEncodeAndDrop(name='Fare')),\n",
    "                       #('encode_age', OneHotEncodeAndDrop(name='Age')),\n",
    "                       #('encode_Pclass', OneHotEncodeAndDrop(name='Pclass')),\n",
    "                       #('combine_fsize', CombineCategoricalValues(name='family_size', rule={'what': ['5','6', '7','8','9','10','11'], 'to': '5'})),\n",
    "                       #('encode_fsize', OneHotEncodeAndDrop(name='family_size')),\n",
    "                       \n",
    "                       #drop first name, family name\n",
    "                       ('drop_last', DropColumns(names=['first_name','family_name', 'Name'])),\n",
    "                       ('show_data', ShowDataHead())\n",
    "                      ]\n",
    "\n",
    "preprocessing_pipeline = Pipeline(steps=preprocessing_steps)\n",
    "combined_processed = preprocessing_pipeline.fit_transform(combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
